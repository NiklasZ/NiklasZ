
This file covers all classes taken during my MSc.

| **Course Name**                       | **Description**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | **Coursework**                                                          |
|---------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|
| **Deep Learning and Neural Networks** | maximum likelihood estimation, softmax, gradient descent, activation functions, backpropagation (computation graph, forward pass, backward pass), training (initialisation, batch normalisation, regularisation, dropout), transfer learning, data augmentation, multitask learning, optimisers (momentum, nesterov, adagrad, rmsprop, adam, second order), fully-connected neural network, convolutional neural network, recurrent neural network, autoencoders, generative adversarial neural networks                                                                                                                                                                                                                                                                                                    | Class exercises in math and python and [class project](https://github.com/NiklasZ/deep-battleships) implenting a DQN   |
| **Large-scale Data Mining**           | feature extraction (word-vec embeddings, TF-IDF, neural latent space), dimensionality reduction (SVD, PCA, NMF), classification (SVM, logistic, naive bayes), clustering (k-means, UMAP, HDBSCAN), recommender systems (collaborative filtering, naive filter, NMF filter, k-nearest-neighbour), regression (linear, polynomial, neural networks, random forest, light gradient boosting), time-series prediction                                                                                                                                                                                                                                                                                                                                                                                           | Various ML [class projects](https://github.com/NiklasZ/large-scale-data-mining-projects) in Python                                |
| **Large-scale Machine Learning**      | learning rates (momentum, nesterov, adagrad, rmsprop, adam, adahessian), variance reduction (stochastic average gradient, SAGA, stochastic variance-reduced gradient descent), gradient descent (parallel, Hogwild, distributed), asynchrony noise and reproducibility, map-reduce, federated learning (averaging, heterogeneity challenge, fairness, security, privacy), maximisation (modular, submodular, supermodular), greedy algorithm (parallel, GreeDI), data selection (importance sampling, forgettability, datapoint scoring, coresets), training robustness (noise, poisoned data), neural network pruning (weight magnitude, gradient magnitude, iterative), neural architecture search (sequential, cell-based, hiearchical, one-shot approaches), neural network quantisation                | Class exercises in math and Python with [class project](https://github.com/NiklasZ/large-scale-ml-project) on importance sampling  |
| **Natural Language Processing**       | multi-class perceptron, Kesler construction, multinomial logistic regression, pre-processing (part-of-speech tagging, sequence models, hidden markov model, maximum entropy model, conditional random fields), word representation (bag of words, embeddings), language models (n-gram, recurrent neural network, long-term-short-term network, transformers), machine translation (sequence-to-sequence models), synctatic parsing (grammar, constituency, dependency), semantic parsing                                                                                                                                                                                                                                                                                                                   | Class exercises, and class projects (TODO reference, TODO reference)    |
| **Probability and Statistics**        | axioms of probability, combinatorics, conditional probability, PMF, CDF, PDF, discrete random variables (bernoulli, binomial, geometric, uniform, poisson), continuous random variables (uniform, exponential, gaussian, cauchy, gamma, chi-square, beta), expectation, variance, transform methods (characteristic, moment theorem, probability generation), probability bounds (Markov, Chebyshev, Chernoff), multiple random variables (joint PDF, PMF, marginal probability, covariance), sums of random variables (sample mean, law of large numbers, convergence, central limit theorem)                                                                                                                                                                                                              | Class exercises, mostly math and Matlab                                 |
| **Reinforcement Learning**            | markov decision process, multi-armed bandit, model-based (policy evaluation, policy iteration, value iteration), model-free prediction (monte-carlo, temporal difference), model-free control (on-policy monte-carlo and temporal difference, off-policy monte-carlo and temporal difference), function approximation (deep Q-learning, policy gradients), imitation learning, monte-carlo tree search                                                                                                                                                                                                                                                                                                                                                                                                      | Class project in Python (TODO reference)                                |
| **Robotics - Kinematics**             | spatial transforms, homogenuous transforms, joint types, degrees of freedom, forward kinematics (dh parameters, common normal, skeleton diagrams), inverse kinematics (geometric method, algebraic method, pieper's method)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | Class exercises in math and Matlab and a class project (TODO reference) |
| **Theoretical Statistics**            | Bayesian vs. frequentistic statistics, decision theory, estimators (admissibility, domination, bias, variance), statistic sufficiency (minimum, complete, ancillary), factorisation theorem, Rao-Blackwell theorem, inequalities (Cauchy-Schwartz, Jensen, Young), uniformly minimum variance unbiased (Lehmannâ€“Scheffe), exponential family (full, full-rank, canonical, curved), mean parameters, maximum likelihood estimator, Cramer-Ramer lower bound, Fisher information, Bayes risk, minimax estimators, large-sample theory, Kullback-Leibler divergence, continuous mapping theorem, Slutsky's theorem, stochastic equicontinuity, asymptotic normality, central limit theorem, delta method, asymptotic relative efficiency, confidence intervals, hypothesis testing, generalised likelihood test | Class exercises, entirely math                                          |
